<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="期末复习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据学习记录">
<meta property="og:url" content="http://example.com/2021/06/27/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/index.html">
<meta property="og:site_name" content="muCyaKuCya">
<meta property="og:description" content="期末复习笔记">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619161928.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619163106.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619224509.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620160909.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620164303.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620201955.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620211509.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620213817.png">
<meta property="og:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620214142.png">
<meta property="article:published_time" content="2021-06-27T07:52:01.000Z">
<meta property="article:modified_time" content="2021-06-27T07:55:04.121Z">
<meta property="article:author" content="muCyaKuCya">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619161928.jpg">

<link rel="canonical" href="http://example.com/2021/06/27/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>大数据学习记录 | muCyaKuCya</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">muCyaKuCya</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/27/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="muCyaKuCya">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="muCyaKuCya">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          大数据学习记录
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-06-27 15:52:01 / Modified: 15:55:04" itemprop="dateCreated datePublished" datetime="2021-06-27T15:52:01+08:00">2021-06-27</time>
            </span>

          
            <div class="post-description">期末复习笔记</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="大数据学习记录"><a href="#大数据学习记录" class="headerlink" title="大数据学习记录"></a>大数据学习记录</h1><h2 id="大数据概念"><a href="#大数据概念" class="headerlink" title="大数据概念"></a>大数据概念</h2><ul>
<li>大数据:指无法在一定时间范围内用常规软件工具进行捕捉,管理和处理的数据集合,是需要新处理模式才能具有更强的决策力,洞察力和流程优化能力的海量,高增长率和多样化的信息资产<ul>
<li>主要解决:采集,存储和计算</li>
</ul>
</li>
</ul>
<h2 id="大数据特点"><a href="#大数据特点" class="headerlink" title="大数据特点"></a>大数据特点</h2><ul>
<li>Volume(大量)</li>
<li>Velocity(高速)</li>
<li>Variety(多样)<br>数据分为<strong>结构化数据</strong>和<strong>非结构化数据</strong></li>
<li>Value(低价值密度)<br>如何快速对有价值数据”提纯”成为目前大数据背景下待解决的难题</li>
</ul>
<h2 id="Hadoop入门"><a href="#Hadoop入门" class="headerlink" title="Hadoop入门"></a>Hadoop入门</h2><ul>
<li><p>学习路线</p>
<ul>
<li><p>概念</p>
<ul>
<li>Hadoop是什么</li>
<li>Hadoop发展历史</li>
<li>Hadoop的三大发行版本</li>
<li>Hadoop的优势</li>
<li>Hadoop的组成</li>
<li>大数据技术生态体系</li>
<li>推荐系统案例</li>
</ul>
</li>
<li><p>环境准备</p>
<ul>
<li>模板虚拟机准备</li>
<li>克隆</li>
<li>安装JKD,Hadoop</li>
</ul>
</li>
<li><p>Hadoop生产集群搭建</p>
<ul>
<li>本地模式</li>
<li>完全分布式集群 ( <strong>开发和面试的重点</strong> )</li>
</ul>
</li>
<li><p>常见错误的解决方案</p>
</li>
</ul>
</li>
</ul>
<h3 id="Hadoop是什么"><a href="#Hadoop是什么" class="headerlink" title="Hadoop是什么"></a>Hadoop是什么</h3><ul>
<li><p>Hadoop是一个由Apache基金会所开发的<strong>分布式系统基础架构</strong></p>
</li>
<li><p>主要解决,海量数据的存储和海量数据的分析计算问题</p>
</li>
<li><p>广义上来说,Hadoop通常是指一个更广泛的概念—-Hadoop生态圈</p>
</li>
</ul>
<h3 id="Hadoop发展历史"><a href="#Hadoop发展历史" class="headerlink" title="Hadoop发展历史"></a>Hadoop发展历史</h3><ul>
<li><p>创始人: Doug Cutting</p>
</li>
<li><p>目的:为了实现与Google类似的全文搜索功能,他在Lucene框架基础上进行优化升级,查询引擎和索引引擎.</p>
</li>
<li><p>2001年底Lucene成为Apache基金会的一个子项目</p>
</li>
<li><p>学习和模仿Google解决这些问题的办法:微型版Nutch</p>
</li>
<li><p>可以说Google是Hadoop的思想之源(Google在大数据方面的三篇论文):</p>
<ul>
<li>GFS —&gt;HDFS</li>
<li>Map-Reduce —&gt;MR</li>
<li>BigTable —&gt;HBase</li>
</ul>
</li>
<li><p>2003年-2004年,Google公开了部分GFS和MapReduce思想的细节,以此为基础Doug Cutting等人用了<strong>2年业余时间</strong>实现了DFS和MapReduce机制,使Nutch性能飙升</p>
</li>
<li><p>2005年Hadoop作为Lucene子项目Nutch 的一部分正式引入Apache基金会</p>
</li>
<li><p>2006年3月份,Map-Reduce和Nutch Distributed File System(<strong>NDFS</strong>)分别被纳入到Hadoop项目中.Hadoop就此正式诞生,标志着大数据时代来临</p>
</li>
</ul>
<h3 id="Hadoop的三大发行版本"><a href="#Hadoop的三大发行版本" class="headerlink" title="Hadoop的三大发行版本"></a>Hadoop的三大发行版本</h3><ul>
<li>Apache : 最原始(最基础)的版本 2006年</li>
<li>Cloudera : 内部集成了很多大数据框架,对应产品CDH 2008年</li>
<li>Hortonworks : 文档较好,对应产品 HDP 2011年</li>
</ul>
<h3 id="Hadoop优势-4高"><a href="#Hadoop优势-4高" class="headerlink" title="Hadoop优势(4高)"></a>Hadoop优势(4高)</h3><ul>
<li>高可靠性 : Hadoop底层维护多个数据副本,所以即使Hadoop某个计算元素或存储出现故障,也不会导致数据的丢失</li>
<li>高拓展性 : 在集群间分配任务数据,可方便的拓展数以千计的节点</li>
<li>高效性 : 在MapReduce的思想下,Hadoop是并行工作的,以加快任务处理速度</li>
<li>高容错性 : 能够自动将失败的任务重新分配</li>
</ul>
<h3 id="Hadoop的组成-面试重点"><a href="#Hadoop的组成-面试重点" class="headerlink" title="Hadoop的组成(面试重点)"></a>Hadoop的组成(<strong>面试重点</strong>)</h3><h4 id="Hadoop1-x组成-Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度-耦合性较大"><a href="#Hadoop1-x组成-Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度-耦合性较大" class="headerlink" title="Hadoop1.x组成    (Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度,耦合性较大)"></a>Hadoop1.x组成    (Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度,耦合性较大)</h4><ul>
<li>MapReduce(计算+资源调度)</li>
<li>HDFS(数据存储)</li>
<li>Common(辅助工具)</li>
</ul>
<h4 id="Hadoop2-x组成-增加了Yarn-只负责资源调度"><a href="#Hadoop2-x组成-增加了Yarn-只负责资源调度" class="headerlink" title="Hadoop2.x组成    (增加了Yarn,只负责资源调度)"></a>Hadoop2.x组成    (增加了Yarn,只负责资源调度)</h4><ul>
<li>MapReduce(计算)</li>
<li>Yarn(资源调度)</li>
<li>HDFS(数据存储)</li>
<li>Common(辅助工具)</li>
</ul>
<h4 id="Hadoop3-x"><a href="#Hadoop3-x" class="headerlink" title="Hadoop3.x"></a>Hadoop3.x</h4><ul>
<li>Hadoop3.x在组成上没有变化</li>
</ul>
<h3 id="HDFS概述"><a href="#HDFS概述" class="headerlink" title="HDFS概述"></a>HDFS概述</h3><p>Hadoop Distributed File System,简称 HDFS,是一个分布式文件系统</p>
<ul>
<li>NameNode(nn) : 存储文件的元数据,如 文件名,文件目录结构,文件属性,以及每个文件的块列表和块所在的DataNode等</li>
<li>DataNode(dn) : 在本地文件系统存储文件块数据,以及块数据的校验</li>
<li>Secondary NameNode(2nn) : 每隔一段时间对NameNode元数据备份</li>
</ul>
<h3 id="YARN架构概述"><a href="#YARN架构概述" class="headerlink" title="YARN架构概述"></a>YARN架构概述</h3><ul>
<li>ResourceManager(RM)  : 整个集群资源(内存,CPU等)的老大</li>
<li>NodeManager(Nm) : 单个节点服务器资源老大</li>
<li>ApplicationMaster(AM) : 单个任务运行的老大</li>
<li>Container : 容器,相当于一台独立的服务器,里面封装了任务运行所需要的资源,如内存,CPU,磁盘,网络等</li>
</ul>
<p>客户端可以有多个<br>集群上可以运行多个ApplicationMaster<br>每个NodeManager上可以有多个Container</p>
<h3 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h3><p>MapReduce将计算过程分为两个阶段 : Map 和 Reduce</p>
<ul>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总</li>
</ul>
<h3 id="HDFS-YARN-MapReduce三者关系"><a href="#HDFS-YARN-MapReduce三者关系" class="headerlink" title="HDFS , YARN , MapReduce三者关系"></a>HDFS , YARN , MapReduce三者关系</h3><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619161928.jpg" style="zoom: 80%;" />



<h2 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h2><p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619163106.jpg" alt="批注 2021-06-19 163047"></p>
<h1 id="CentOS-7"><a href="#CentOS-7" class="headerlink" title="CentOS 7"></a>CentOS 7</h1><h2 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u291-linux-x64.tar.gz -C &#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure>

<h2 id="JDK环境配置"><a href="#JDK环境配置" class="headerlink" title="JDK环境配置"></a>JDK环境配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_219</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">java</span><br></pre></td></tr></table></figure>



<h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-3.2.2.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure>

<h2 id="Hadoop环境配置"><a href="#Hadoop环境配置" class="headerlink" title="Hadoop环境配置"></a>Hadoop环境配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HADOOP_HOME</span></span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.2.2</span><br><span class="line"></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line"></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line">hadoop</span><br></pre></td></tr></table></figure>

<h2 id="Hadoop目录"><a href="#Hadoop目录" class="headerlink" title="Hadoop目录"></a>Hadoop目录</h2><blockquote>
<p>bin : HDFS , YARN , MAPRED<br>etc<br>sbin<br>lib</p>
</blockquote>
<h2 id="Hadoop运行的三种模式"><a href="#Hadoop运行的三种模式" class="headerlink" title="Hadoop运行的三种模式"></a>Hadoop运行的三种模式</h2><ul>
<li>本地模式<ul>
<li>数据存储在Linux本地</li>
<li>测试偶尔用一下</li>
</ul>
</li>
<li>伪分布模式<ul>
<li>数据存储在HDFS</li>
<li>公司中比较差钱</li>
</ul>
</li>
<li>全分布模式<ul>
<li>数据存储在HDFS / 多台服务器工作</li>
<li>企业里面大量使用</li>
</ul>
</li>
</ul>
<h2 id="Hadoop本地模式示例-官方WordCount"><a href="#Hadoop本地模式示例-官方WordCount" class="headerlink" title="Hadoop本地模式示例(官方WordCount)"></a>Hadoop本地模式示例(官方WordCount)</h2><ul>
<li><p>新建wcinput文件夹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir </span><br></pre></td></tr></table></figure>
</li>
<li><p>进入wcinput并新建word.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd wcinput</span><br><span class="line"></span><br><span class="line">vim word.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>填写名字,空格分割</p>
</li>
<li><p>运行Hadoop</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.2.jar wordcount wcinput&#x2F; .&#x2F;wcoutput</span><br></pre></td></tr></table></figure>

<p><strong>注意输出目录必须不存在</strong></p>
</li>
<li><p>查看运行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd wcoutput&#x2F;</span><br><span class="line">cat part-r-00000 </span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210619224509.jpg"></p>
</li>
</ul>
<h2 id="完全分布式运行模式-开发重点"><a href="#完全分布式运行模式-开发重点" class="headerlink" title="完全分布式运行模式(开发重点)"></a>完全分布式运行模式(开发重点)</h2><blockquote>
<p>准备3台客户机(关闭防火墙,静态IP,主机名称)</p>
<p>安装JDK</p>
<p>配置环境变量</p>
<p>安装Hadoop</p>
<p>配置环境变量</p>
<p>配置集群</p>
<p>单点启动</p>
<p>配置SSH</p>
<p>群起并测试集群</p>
</blockquote>
<h3 id="编写集群分发脚本-xsync"><a href="#编写集群分发脚本-xsync" class="headerlink" title="编写集群分发脚本 xsync"></a>编写集群分发脚本 xsync</h3><h4 id="scp-secure-copy-安全拷贝"><a href="#scp-secure-copy-安全拷贝" class="headerlink" title="scp(secure copy) 安全拷贝"></a>scp(secure copy) 安全拷贝</h4><ul>
<li><p>scp定义</p>
<ul>
<li>scp可以实现服务器与服务器之间的数据拷贝 (from server 1 to server2)</li>
</ul>
</li>
<li><p>基本语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp		-r		$pdir&#x2F;$fname			$user@$host:$pdir&#x2F;$fname</span><br><span class="line">命令	  递归     要拷贝的文件路径&#x2F;名称      目的地用户@主机:目的地路径&#x2F;名称</span><br></pre></td></tr></table></figure>
</li>
<li><p>实际使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">从Hadoop102 推 数据到Hadoop103</span><br><span class="line">[taki@hadoop102 module]$ scp -r jdk1.8.0_291&#x2F; taki@hadoop103:&#x2F;opt&#x2F;module&#x2F;</span><br><span class="line"></span><br><span class="line">从Hadoop103 拉 数据到Hadoop103(本机)</span><br><span class="line">[taki@hadoop103 module]$ scp -r taki@hadoop102:&#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2 .&#x2F;</span><br><span class="line"></span><br><span class="line">在Hadoop103,从Hadoop102,拉数据,到Hadoop104</span><br><span class="line">[taki@hadoop103 module]$ scp -r taki@hadoop102:&#x2F;opt&#x2F;module&#x2F;* taki@hadoop104:&#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="rsync远程同步工具"><a href="#rsync远程同步工具" class="headerlink" title="rsync远程同步工具"></a>rsync远程同步工具</h4><ul>
<li><p>rsync定义</p>
<ul>
<li>rsync主要用于备份和镜像.具有速度快,避免复制相同内容和支持符号链接的优点</li>
</ul>
</li>
<li><p><strong>rsync和scp区别</strong></p>
<ul>
<li>用rsync做文件的复制要比scp的速度快,rsync只对差异文件做更新.scp是把所有文件都复制过去</li>
</ul>
</li>
<li><p>基本语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync		-av			$pdir&#x2F;$fname			$user@$host:$pdir&#x2F;$fname</span><br><span class="line">命令        选项参数       要拷贝的文件路径&#x2F;名称     目的地用户@主机:目的地路径&#x2F;名称</span><br></pre></td></tr></table></figure>

<blockquote>
<p>选项参数说明</p>
<p>-a : 归档拷贝</p>
<p>-v : 显示复制过程</p>
</blockquote>
</li>
<li><p>案例实操</p>
<ul>
<li><p>删除Hadoop103中/opt/module/hadoop-3.2.2/wcinput</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf wcinput&#x2F;</span><br></pre></td></tr></table></figure>
</li>
<li><p>同步Hadoop102中的/opt/module/hadoop-3.2.2到Hadoop103</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 module]$ rsync -av hadoop-3.2.2&#x2F; taki@hadoop103:&#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h4 id="xsync-集群分发脚本"><a href="#xsync-集群分发脚本" class="headerlink" title="xsync 集群分发脚本"></a>xsync 集群分发脚本</h4><ul>
<li><p>需求 :  循环复制文件到所有节点的相同目录下</p>
</li>
<li><p>需求分析 : </p>
<ul>
<li><p>rsync命令原始拷贝 : </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av    &#x2F;opt&#x2F;module        taki@hadoop103:&#x2F;opt&#x2F;</span><br></pre></td></tr></table></figure>
</li>
<li><p>期望脚本 : xsync要同步的文件名称</p>
</li>
<li><p>期望脚本在任何路径都能使用(脚本放在声明了全局环境变量的路径)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $PATH</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>脚本实现</p>
<ul>
<li><p>在/home/taki/bin目录下创建xsync文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;home&#x2F;taki</span><br><span class="line">mkdir bin</span><br><span class="line">cd bin</span><br><span class="line">vim xsync</span><br></pre></td></tr></table></figure>
</li>
<li><p>在该文件中编写如下代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1.判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2.遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo ========  $host  ========</span><br><span class="line">    #3.遍历所有目录,挨个发送</span><br><span class="line"></span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        #4.判断文件是否存在</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">            then</span><br><span class="line">                #5.获取父目录</span><br><span class="line">                pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line"></span><br><span class="line">                #6.获取当前文件的名称</span><br><span class="line">                fname=$(basename $file)</span><br><span class="line">                ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">            else</span><br><span class="line">                echo $file does not exists!</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
</li>
<li><p>赋予脚本可执行权限</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 xsync</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>分发环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 ~]$ sudo .&#x2F;bin&#x2F;xsync &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>刷新环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="SSH无密登陆配置"><a href="#SSH无密登陆配置" class="headerlink" title="SSH无密登陆配置"></a>SSH无密登陆配置</h3><ul>
<li><p>配置ssh</p>
<ul>
<li><p>基本语法</p>
<blockquote>
<p>ssh另一台电脑的IP地址</p>
</blockquote>
</li>
<li><p>ssh连接时出现Host key verification failed的解决方法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh hadoop103</span><br><span class="line"></span><br><span class="line">如果出现如下内容</span><br><span class="line">Are you sure you want to continue connecting(yes&#x2F;no)?</span><br><span class="line">输入yes,并回车</span><br></pre></td></tr></table></figure>
</li>
<li><p>退回到hadoop102</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>无密钥配置</p>
<ul>
<li><p>免密登录原理<br><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620160909.jpg"></p>
</li>
<li><p>生成公钥和私钥</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
</li>
<li><p>拷贝公钥到hadoop103</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h3 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h3><ul>
<li><p>集群部署规划</p>
<p>注意:</p>
<blockquote>
<p>NameNode 和 SecondaryNameNode 不要安装在同一台服务器<br>ResourceManager 也很消耗内存,不要和NameNode , SecondaryNameNode 配置在同一台机器上</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">hadoop102</th>
<th align="center">hadoop103</th>
<th align="center">hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td align="center">HDFS</td>
<td align="center">NameNode<br />DataNode</td>
<td align="center">DataNode</td>
<td align="center">SecondaryNameNode<br />DataNode</td>
</tr>
<tr>
<td align="center">YARN</td>
<td align="center">NodeManager</td>
<td align="center">ResourceManager<br />NodeManager</td>
<td align="center">NodeManager</td>
</tr>
</tbody></table>
</blockquote>
</li>
</ul>
<ul>
<li><p>配置文件说明</p>
<blockquote>
<p>Hadoop配置文件分两类 : 默认配置文件和自定义配置文件,只有用户想修改某一默认配置值时,才需要修改自定义配置文件,更改相应属性值</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620164303.jpg"></p>
</li>
<li><p>配置自定义文件-后补</p>
</li>
<li><p>在集群上分发配置好的hadoop配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ xsync &#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2&#x2F;etc&#x2F;hadoop&#x2F;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><ul>
<li><p>配置workers</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2&#x2F;etc&#x2F;hadoop&#x2F;workers</span><br><span class="line"></span><br><span class="line">在该文件中增加如下内容:</span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意 : 该文件中添加的内容结尾不允许有空格,文件中不允许有空行</p>
<p>同步所有节点配置文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ xsync &#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2.etc</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动集群</p>
<ul>
<li><p>如果集群是第一次启动,需要在hadoop102节点格式化NmaeNode(注意:格式化NameNode,会产生新的集群id,导致NameNode和DataNode的集群id不一致,集群找不到以往数据.如果集群在运行过程中报错,需要重新格式化NameNode的话,一定要先停止namenode和datanode进程,并且要删除所有机器的data和logs目录,然后再进行格式化)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>启动HDFS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ sbin&#x2F;start-dfs.sh </span><br></pre></td></tr></table></figure>
</li>
<li><p>在Web端查看HDFS的NameNode</p>
<blockquote>
<p>浏览器中输入 : <a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a></p>
<p>查看HDFS上存储的数据信息</p>
</blockquote>
</li>
<li><p>在配置了ResourceManager的节点(hadoop103)启动YARN</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 hadoop-3.2.2]$ sbin&#x2F;start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>在Web端查看YARN的ResourceManager</p>
<blockquote>
<p>浏览器中输入 : <a target="_blank" rel="noopener" href="http://hadoop103:8080/">http://hadoop103:8080</a></p>
<p>查看YARN上运行的Job信息</p>
</blockquote>
</li>
</ul>
<h3 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h3><ul>
<li><p>上传文件到集群</p>
<blockquote>
<p>上传小文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ hadoop fs -mkdir &#x2F;wcinput</span><br><span class="line">[taki@hadoop102 hadoop-3.2.2]$ hadoop fs -put wcinput&#x2F;word.txt &#x2F;wcinput</span><br></pre></td></tr></table></figure>

<blockquote>
<p>上传大文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ hadoop fs -put &#x2F;opt&#x2F;software&#x2F;jdk-8u291-linux-x64.tar.gz &#x2F;</span><br></pre></td></tr></table></figure>
</li>
<li><p>上传文件后查看文件存放在上面位置</p>
<blockquote>
<p>查看HDFS文件存储路径</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;module&#x2F;hadoop-3.2.2&#x2F;data&#x2F;dfs&#x2F;data&#x2F;current&#x2F;BP-1460077924-192.168.10.102-1624182202719&#x2F;current&#x2F;finalized&#x2F;subdir0&#x2F;subdir0</span><br></pre></td></tr></table></figure>

<blockquote>
<p>查看HDFS在磁盘存储文件内容</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 subdir0]$ cat blk_1073741825</span><br><span class="line">czy czy</span><br><span class="line">fwj fwj</span><br><span class="line">lhc</span><br><span class="line">zhb</span><br><span class="line">lwt</span><br></pre></td></tr></table></figure>
</li>
<li><p>拼接</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 subdir0]$ cat blk_1073741826 &gt;&gt; tmp.tar.gz</span><br><span class="line">[taki@hadoop102 subdir0]$ cat blk_1073741827 &gt;&gt; tmp.tar.gz </span><br><span class="line">[taki@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop104 software]$ hadoop fd -get &#x2F;jdk-8u291-linux-x64.tat.gz .&#x2F;</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行wordcout程序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.2.2.jar wordcount &#x2F;wcinput &#x2F;wcoutput</span><br></pre></td></tr></table></figure>
</li>
<li><p>处理崩溃</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">停止进程</span><br><span class="line">[taki@hadoop102 hadoop-3.2.2]$ sbin&#x2F;stop-dfs.sh</span><br><span class="line"></span><br><span class="line">删除每个集群上的data logs</span><br><span class="line">rm -rf data&#x2F; logs&#x2F;</span><br><span class="line"></span><br><span class="line">格式化HDFS</span><br><span class="line">hdfs namenode -format</span><br><span class="line"></span><br><span class="line">启动集群</span><br><span class="line">sbin&#x2F;start-dfs.sh</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><blockquote>
<p>为了查看程序的历史运行情况,需要配置一下历史服务器.具体配置步骤如下 : </p>
</blockquote>
<ul>
<li><p>配置mapred-site.xml</p>
<blockquote>
<p>在该文件里面增加如下配置</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 历史服务器端地址 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;hadoop102:10020&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line"> </span><br><span class="line">&lt;!-- 历史服务器 web 端地址 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;hadoop102:19888&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br></pre></td></tr></table></figure>
</li>
<li><p>分发配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ xsync mapred-site.xml </span><br></pre></td></tr></table></figure>
</li>
<li><p>重启YARN</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 hadoop-3.2.2]$ sbin&#x2F;stop-yarn.sh</span><br><span class="line">[taki@hadoop103 hadoop-3.2.2]$ sbin&#x2F;start-yarn.sh </span><br></pre></td></tr></table></figure>
</li>
<li><p>在hadoop102启动历史服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop-3.2.2]$ bin&#x2F;mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看JobHistory</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p>
</blockquote>
</li>
</ul>
<h3 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h3><blockquote>
<p>概念 : 应用运行完成以后,将程序运行日志信息上传到HDFS系统上</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620201955.jpg"></p>
<blockquote>
<p>日志聚集功能好处 : 可以方便的查看到程序运行详情,方便开发调试</p>
<p>注意 : 开启日志聚集功能 , 需要重新启动NodeManager , ResourceManager 和 HistoryServer</p>
</blockquote>
<p>开启日志聚集功能具体步骤如下 : </p>
<ul>
<li><p>配置yarn-site.xml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ vim yarn-site.xml </span><br></pre></td></tr></table></figure>

<blockquote>
<p>在该文件里面增加如下配置</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 开启日志聚集功能 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;true&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;!-- 设置日志聚集服务器地址 --&gt; </span><br><span class="line">&lt;property&gt;   </span><br><span class="line">    &lt;name&gt;yarn.log.server.url&lt;/name&gt;   </span><br><span class="line">    &lt;value&gt;http://hadoop102:19888/jobhistory/logs&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;!-- 设置日志保留时间为 7 天 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;604800&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br></pre></td></tr></table></figure>
</li>
<li><p>分发配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ xsync yarn-site.xml </span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭NodeManager , ResourceManager 和 HistoryServer</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 hadoop-3.2.2]$ sbin&#x2F;stop-yarn.sh</span><br><span class="line">[taki@hadoop102 hadoop-3.2.2]$ mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动NodeManager , ResourceManager 和 HistoryServer</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 ~]$ start-yarn.sh</span><br><span class="line">[taki@hadoop102 hadoop-3.2.2]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h3><ul>
<li><p>各个模块分开启动/停止(配置ssh是前提) <strong>常用</strong></p>
<blockquote>
<p>整体启动/停止HDFS</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh&#x2F;stop-dfs.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>整体启动/停止YARN</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh&#x2F;stop-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>各个服务组件逐一启动/停止</p>
<blockquote>
<p>分别启动/停止HDFS组件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start&#x2F;stop namenode&#x2F;datanode&#x2F;secondarynamenode</span><br></pre></td></tr></table></figure>

<blockquote>
<p>启动/停止YARN</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn --daemon start&#x2F;stop resourcemanager&#x2F;nodemanager</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="编写Hadoop集群常用脚本"><a href="#编写Hadoop集群常用脚本" class="headerlink" title="编写Hadoop集群常用脚本"></a>编写Hadoop集群常用脚本</h3><ul>
<li><p>Hadoop集群启停脚本(包含HDFS,YARN,HIstoryserver) : myhadoop.sh</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 ~]$ cd &#x2F;home&#x2F;taki&#x2F;bin</span><br><span class="line">[taki@hadoop103 bin]$ vim myhadoop.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>输入如下内容</p>
<p>记住：写脚本的时候能写绝对路径，千万不要写相对路径！</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span> </span><br><span class="line"> </span><br><span class="line">if [ $# -lt 1 ] </span><br><span class="line">then </span><br><span class="line">    echo &quot;No Args Input...&quot; </span><br><span class="line">    exit ; </span><br><span class="line">fi </span><br><span class="line"> </span><br><span class="line">case $1 in </span><br><span class="line">&quot;start&quot;) </span><br><span class="line">        echo &quot; =================== 启动 hadoop 集群 ===================&quot; </span><br><span class="line"> </span><br><span class="line">        echo &quot; --------------- 启动 hdfs ---------------&quot; </span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop-3.2.2/sbin/start-dfs.sh&quot; </span><br><span class="line">        echo &quot; --------------- 启动 yarn ---------------&quot; </span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop-3.2.2/sbin/start-yarn.sh&quot; </span><br><span class="line">        echo &quot; --------------- 启动 historyserver ---------------&quot; </span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop-3.2.2/bin/mapred --daemon start historyserver&quot; </span><br><span class="line">;; </span><br><span class="line">&quot;stop&quot;) </span><br><span class="line">        echo &quot; =================== 关闭 hadoop 集群 ===================&quot; </span><br><span class="line"> </span><br><span class="line">        echo &quot; --------------- 关闭 historyserver ---------------&quot; </span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop-3.2.2/bin/mapred --daemon stop historyserver&quot; </span><br><span class="line">        echo &quot; --------------- 关闭 yarn ---------------&quot; </span><br><span class="line">        ssh hadoop103 &quot;/opt/module/hadoop-3.2.2/sbin/stop-yarn.sh&quot; </span><br><span class="line">        echo &quot; --------------- 关闭 hdfs ---------------&quot; </span><br><span class="line">        ssh hadoop102 &quot;/opt/module/hadoop-3.2.2/sbin/stop-dfs.sh&quot; </span><br><span class="line">;; </span><br><span class="line">*) </span><br><span class="line">    echo &quot;Input Args Error...&quot; </span><br><span class="line">;; </span><br><span class="line">esac </span><br></pre></td></tr></table></figure>

<blockquote>
<p>保存后退出，然后赋予脚本执行权限</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 myhadoop.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看三台服务器Java进程脚本 : jpsall</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop103 ~]$ cd &#x2F;home&#x2F;taki&#x2F;bin</span><br><span class="line">[taki@hadoop103 bin]$ vim jpsall</span><br></pre></td></tr></table></figure>

<blockquote>
<p>输入如下内容</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span> </span><br><span class="line"> </span><br><span class="line">for host in hadoop102 hadoop103 hadoop104 </span><br><span class="line">do </span><br><span class="line">        echo =============== $host =============== </span><br><span class="line">        ssh $host jps  </span><br><span class="line">done </span><br></pre></td></tr></table></figure>

<blockquote>
<p>保存后退出,然后赋予脚本执行权限</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 jpsall</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发/home/taki/bin目录,保证自定义脚本在三台机器上都可以使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync &#x2F;home&#x2F;taki&#x2F;bin</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="常用端口号说明-面试题"><a href="#常用端口号说明-面试题" class="headerlink" title="常用端口号说明(面试题)"></a>常用端口号说明(面试题)</h3><table>
<thead>
<tr>
<th align="center">端口名称</th>
<th align="center">Hadoop2.x</th>
<th align="center">Hadoop3.x</th>
</tr>
</thead>
<tbody><tr>
<td align="center">HDFS NameNode内部通信端口</td>
<td align="center">8020 / 9000</td>
<td align="center">8020 / 9000 / 9820</td>
</tr>
<tr>
<td align="center">HDFS NameNode HTTP UI</td>
<td align="center">50070</td>
<td align="center">9870</td>
</tr>
<tr>
<td align="center">Yarn/MapReduce 查看执行任务端口</td>
<td align="center">8088</td>
<td align="center">8088</td>
</tr>
<tr>
<td align="center">历史服务器通信端口</td>
<td align="center">19888</td>
<td align="center">19888</td>
</tr>
</tbody></table>
<h3 id="常用的配置文件-面试题"><a href="#常用的配置文件-面试题" class="headerlink" title="常用的配置文件(面试题)"></a>常用的配置文件(面试题)</h3><table>
<thead>
<tr>
<th align="center">Hadoop版本</th>
<th align="center">配置文件</th>
</tr>
</thead>
<tbody><tr>
<td align="center">3.x</td>
<td align="center">core-site.xml<br />hdfs-site.xml<br />yarn-site.xml<br />mapred-site.xml<br />workers</td>
</tr>
<tr>
<td align="center">2.x</td>
<td align="center">core-site.xml<br />hdfs-site.xml<br />yarn-site.xml<br />mapred-site.xml<br />slaves</td>
</tr>
</tbody></table>
<h3 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h3><blockquote>
<p>生产环境 : 如果服务器能连接外网,不需要时间同步.<br>                 如果服务器连接不了外网,需要时间同步.</p>
</blockquote>
<img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620211509.jpg" style="zoom:50%;" />

<ul>
<li><p>时间服务器配置(必须root用户)</p>
<blockquote>
<p>查看所有节点ntpd服务状态和开机自启动状态</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status ntpd</span><br><span class="line">sudo systemctl start ntpd ntpd</span><br><span class="line">sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure>

<blockquote>
<p>修改hadoop102的ntp.conf配置文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;ntp.conf</span><br></pre></td></tr></table></figure>

<blockquote>
<blockquote>
<p>修改内容如下</p>
<p>a),修改1(授权192.168.10.0-192.168.10.255网段上的所有机器可以从这台机器上查询和同步时间)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">改#restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line">为 restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure>

<p>b)修改2(集群在局域网中，不使用其他互联网上的时间）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">改</span><br><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br><span class="line">为</span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br></pre></td></tr></table></figure>

<p>c)添加 3 (当该节点丢失网络连接,依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure>
</blockquote>
<p>修改hadoop102的/etc/sysconfig/ntpd文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;sysconfig&#x2F;ntpd</span><br><span class="line"></span><br><span class="line">增加内容如下</span><br><span class="line">(让硬件时间与系统时间一起同步)</span><br><span class="line">SYNC_HWCLOCK&#x3D;yes</span><br></pre></td></tr></table></figure>

<p>重新启动 ntpd 服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start ntpd</span><br></pre></td></tr></table></figure>

<p>设置 ntpd 服务开机启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>其他机器配置（必须 root 用户）</p>
<blockquote>
<p>关闭所有节点上 ntp 服务和自启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop ntpd</span><br><span class="line">sudo systemctl disable ntpd</span><br><span class="line">sudo systemctl stop ntpd</span><br><span class="line">sudo systemctl disable ntpd</span><br></pre></td></tr></table></figure>

<p>在其他机器配置 1 分钟与时间服务器同步一次</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo crontab -e</span><br><span class="line">编写定时任务如下：</span><br><span class="line">*&#x2F;1 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate hadoop102</span><br></pre></td></tr></table></figure>

<p>修改任意机器时间</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo date -s &quot;2021-9-11 11:11:11&quot;</span><br></pre></td></tr></table></figure>

<p>1 分钟后查看机器是否与时间服务器同步</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo date</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<h2 id="常见错误及解决方案"><a href="#常见错误及解决方案" class="headerlink" title="常见错误及解决方案"></a>常见错误及解决方案</h2><h3 id="防火墙没关闭-或者没有启动-YARN"><a href="#防火墙没关闭-或者没有启动-YARN" class="headerlink" title="防火墙没关闭 , 或者没有启动 YARN"></a>防火墙没关闭 , 或者没有启动 YARN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO client.RMProxy: Connecting to ResourceManager at hadoop108&#x2F;192.168.10.108:8032 </span><br></pre></td></tr></table></figure>

<h3 id="主机名称配置错误"><a href="#主机名称配置错误" class="headerlink" title="主机名称配置错误"></a>主机名称配置错误</h3><blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/114847016">Hadoop入门(二)——VMware15.5虚拟网络设置+Windows10的IP地址配置+CentOS7静态IP设置（图文详解步骤2021）</a></p>
</blockquote>
<h3 id="IP-地址配置错误"><a href="#IP-地址配置错误" class="headerlink" title="IP 地址配置错误"></a>IP 地址配置错误</h3><blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/114847016">Hadoop入门(二)——VMware15.5虚拟网络设置+Windows10的IP地址配置+CentOS7静态IP设置（图文详解步骤2021）</a></p>
</blockquote>
<h3 id="ssh-没有配置好"><a href="#ssh-没有配置好" class="headerlink" title="ssh 没有配置好"></a>ssh 没有配置好</h3><blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/115189748">Hadoop入门(九)——SSH免密登录 配置（图文详解步骤2021）</a></p>
</blockquote>
<h3 id="root-用户和taki-两个用户启动集群不统一"><a href="#root-用户和taki-两个用户启动集群不统一" class="headerlink" title="root 用户和taki 两个用户启动集群不统一"></a>root 用户和taki 两个用户启动集群不统一</h3><blockquote>
<p>通常用taki账号启动集群,最好不要在root上启动集群</p>
</blockquote>
<h3 id="配置文件修改不细心"><a href="#配置文件修改不细心" class="headerlink" title="配置文件修改不细心"></a>配置文件修改不细心</h3><blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/115196370">Hadoop入门(十)——集群配置（图文详解步骤2021）</a></p>
</blockquote>
<h3 id="不识别主机名称"><a href="#不识别主机名称" class="headerlink" title="不识别主机名称"></a>不识别主机名称</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">java.net.UnknownHostException: hadoop102: hadoop102 </span><br><span class="line">        at </span><br><span class="line">java.net.InetAddress.getLocalHost(InetAddress.java:1475) </span><br><span class="line">        at </span><br><span class="line">org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(Job</span><br><span class="line">Submitter.java:146) </span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290) </span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287) </span><br><span class="line">        at  java.security.AccessController.doPrivileged(Native </span><br><span class="line">Method) </span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:415) </span><br></pre></td></tr></table></figure>

<blockquote>
<p>解决办法：<br>（1）主机名称映射没有配<br>在/etc/hosts 文件中添加 192.168.10.102 hadoop102<br>（2）与系统的命令发生冲突<br>主机名称不要起 hadoop hadoop000 等特殊名称</p>
</blockquote>
<h3 id="DataNode-和-NameNode-进程同时只能工作一个"><a href="#DataNode-和-NameNode-进程同时只能工作一个" class="headerlink" title="DataNode 和 NameNode 进程同时只能工作一个"></a>DataNode 和 NameNode 进程同时只能工作一个</h3><blockquote>
<p>参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/116294635">Hadoop入门(十一)——集群崩溃的处理方法（图文详解步骤2021</a>）</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620213817.png"></p>
<h3 id="执行命令不生效-粘贴-Word-中命令时-遇到-和长–没区分开-导致命令失效"><a href="#执行命令不生效-粘贴-Word-中命令时-遇到-和长–没区分开-导致命令失效" class="headerlink" title="执行命令不生效,粘贴 Word 中命令时,遇到-和长–没区分开.导致命令失效"></a>执行命令不生效,粘贴 Word 中命令时,遇到-和长–没区分开.导致命令失效</h3><blockquote>
<p>解决办法：尽量不要粘贴 Word 中代码</p>
</blockquote>
<h3 id="jps-发现进程已经没有，但是重新启动集群，提示进程已经开启。"><a href="#jps-发现进程已经没有，但是重新启动集群，提示进程已经开启。" class="headerlink" title="jps 发现进程已经没有，但是重新启动集群，提示进程已经开启。"></a>jps 发现进程已经没有，但是重新启动集群，提示进程已经开启。</h3><blockquote>
<p>原因是在 Linux 的根目录下/tmp 目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。</p>
</blockquote>
<h3 id="jps-不生效"><a href="#jps-不生效" class="headerlink" title="jps 不生效"></a>jps 不生效</h3><blockquote>
<p>原因：全局变量 hadoop java 没有生效。解决办法：需要 source /etc/profile 文件。</p>
</blockquote>
<h3 id="8088-端口连接不上"><a href="#8088-端口连接不上" class="headerlink" title="8088 端口连接不上"></a>8088 端口连接不上</h3><blockquote>
<p>[taki@hadoop102 桌面]$ `cat /etc/hosts</p>
<p>注释掉如下代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 </span><br><span class="line">#::1         hadoop102 </span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="UI没权限"><a href="#UI没权限" class="headerlink" title="UI没权限"></a>UI没权限</h3><blockquote>
<p>参考参考<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_46413065/article/details/115196370">Hadoop入门(十)——集群配置（图文详解步骤2021）</a></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/muCyaKuCya/image/main/20210620214142.png"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[taki@hadoop102 hadoop]$ vim core-site.xml</span><br><span class="line"></span><br><span class="line">添加如下代码</span><br><span class="line">&lt;!-- 配置 HDFS 网页登录使用的静态用户为 taki --&gt; </span><br><span class="line">    &lt;property&gt; </span><br><span class="line">        &lt;name&gt;hadoop.http.staticuser.user&lt;&#x2F;name&gt; </span><br><span class="line">        &lt;value&gt;taki&lt;&#x2F;value&gt; </span><br><span class="line">    &lt;&#x2F;property&gt; </span><br></pre></td></tr></table></figure>

<h2 id="HDFS-Shell命令上传"><a href="#HDFS-Shell命令上传" class="headerlink" title="HDFS_Shell命令上传"></a>HDFS_Shell命令上传</h2><ul>
<li><p>基本语法</p>
<blockquote>
<p>hadoop fs 具体命令 OR hdfs dfs 具体命令</p>
<p>两个是完全相同的</p>
</blockquote>
</li>
<li><p>常用命令实操</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -help rm</span><br><span class="line"></span><br><span class="line">hadoop fs mkdir &#x2F;sanguo</span><br></pre></td></tr></table></figure>
</li>
<li><p>上传</p>
<blockquote>
<p>-moveFromLocal: 从本地剪切粘贴到HDFS</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim shuguo.txt</span><br><span class="line">输入:</span><br><span class="line">shuguo</span><br><span class="line"></span><br><span class="line">hadoop fs -moveFromLocal .&#x2F;shuguo.txt &#x2F;sanguo</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-copyFromLocal: 从本地文件系统中拷贝文件到HDFS路径去</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim weiguo.txt</span><br><span class="line"></span><br><span class="line">输入:</span><br><span class="line">weiguo</span><br><span class="line"></span><br><span class="line">hadoop fs -copyFromLocal weiguo.txt &#x2F;sanguo</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-put :等同于copyFromLocal,生产环境更习惯使用put</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim wuguo.txt</span><br><span class="line"></span><br><span class="line">输入:</span><br><span class="line">wuguo</span><br><span class="line"></span><br><span class="line">hadoop fs -put .&#x2F;wuguo.txt &#x2F;sanguo</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-appendToFile : 追加一个文件到已经存在的文件末尾</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim liubei.txt</span><br><span class="line">输入:</span><br><span class="line">hadoop fs -appendToFile liubei.txt &#x2F;sanguo&#x2F;shuguo.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载</p>
<blockquote>
<p>-copyToLocal : 从HDFS拷贝到本地</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal &#x2F;sanguo&#x2F;shuguo.txt .&#x2F;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>-get: 等同于copyToLocal,生产环境更习惯用get</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get &#x2F;sanguo&#x2F;shuguo.txt .&#x2F;shuguo2.txt</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="HDFS直接操作"><a href="#HDFS直接操作" class="headerlink" title="HDFS直接操作"></a>HDFS直接操作</h2><blockquote>
<p>-ls:显示目录信息</p>
<p>-cat:显示文件内容</p>
<p>-chgrp,-chmod,-chown: Linux系统中用法一样,修改文件所属权限</p>
<p>-mkdir:创建路径</p>
<p>-cp:从HDFS的一个路径拷贝到HDFS的另一个路径</p>
<p>-mv:在HDFS目录中移动文件</p>
<p>-tail:显示一个文件的末尾1kb的数据</p>
<p>-rm:删除文件或文件夹</p>
<p>-rm -r: 递归删除目录一目录里面内容</p>
<p>-du: 统计文件夹的大小信息  hadoop fs -du -s -h /jinguo</p>
<p>-setrep : 设置HDFS中文件的副本数量(但是得看DataNode的数量)</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/21/My-first-Artical/" rel="prev" title="My first Artical">
      <i class="fa fa-chevron-left"></i> My first Artical
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/07/13/%E5%86%85%E5%AD%98%E7%9A%84%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" rel="next" title="内存的基础知识">
      内存的基础知识 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95"><span class="nav-number">1.</span> <span class="nav-text">大数据学习记录</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E5%BF%B5"><span class="nav-number">1.1.</span> <span class="nav-text">大数据概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%89%B9%E7%82%B9"><span class="nav-number">1.2.</span> <span class="nav-text">大数据特点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E5%85%A5%E9%97%A8"><span class="nav-number">1.3.</span> <span class="nav-text">Hadoop入门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-number">1.3.1.</span> <span class="nav-text">Hadoop是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><span class="nav-number">1.3.2.</span> <span class="nav-text">Hadoop发展历史</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E7%9A%84%E4%B8%89%E5%A4%A7%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC"><span class="nav-number">1.3.3.</span> <span class="nav-text">Hadoop的三大发行版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E4%BC%98%E5%8A%BF-4%E9%AB%98"><span class="nav-number">1.3.4.</span> <span class="nav-text">Hadoop优势(4高)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E7%9A%84%E7%BB%84%E6%88%90-%E9%9D%A2%E8%AF%95%E9%87%8D%E7%82%B9"><span class="nav-number">1.3.5.</span> <span class="nav-text">Hadoop的组成(面试重点)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hadoop1-x%E7%BB%84%E6%88%90-Hadoop%E4%B8%AD%E7%9A%84MapReduce%E5%90%8C%E6%97%B6%E5%A4%84%E7%90%86%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E5%92%8C%E8%B5%84%E6%BA%90%E7%9A%84%E8%B0%83%E5%BA%A6-%E8%80%A6%E5%90%88%E6%80%A7%E8%BE%83%E5%A4%A7"><span class="nav-number">1.3.5.1.</span> <span class="nav-text">Hadoop1.x组成    (Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度,耦合性较大)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hadoop2-x%E7%BB%84%E6%88%90-%E5%A2%9E%E5%8A%A0%E4%BA%86Yarn-%E5%8F%AA%E8%B4%9F%E8%B4%A3%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6"><span class="nav-number">1.3.5.2.</span> <span class="nav-text">Hadoop2.x组成    (增加了Yarn,只负责资源调度)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hadoop3-x"><span class="nav-number">1.3.5.3.</span> <span class="nav-text">Hadoop3.x</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E6%A6%82%E8%BF%B0"><span class="nav-number">1.3.6.</span> <span class="nav-text">HDFS概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">1.3.7.</span> <span class="nav-text">YARN架构概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">1.3.8.</span> <span class="nav-text">MapReduce架构概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-YARN-MapReduce%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB"><span class="nav-number">1.3.9.</span> <span class="nav-text">HDFS , YARN , MapReduce三者关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB"><span class="nav-number">1.4.</span> <span class="nav-text">大数据技术生态体系</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CentOS-7"><span class="nav-number">2.</span> <span class="nav-text">CentOS 7</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E8%A3%85JDK"><span class="nav-number">2.1.</span> <span class="nav-text">安装JDK</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#JDK%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">2.2.</span> <span class="nav-text">JDK环境配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E8%A3%85Hadoop"><span class="nav-number">2.3.</span> <span class="nav-text">安装Hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">2.4.</span> <span class="nav-text">Hadoop环境配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%9B%AE%E5%BD%95"><span class="nav-number">2.5.</span> <span class="nav-text">Hadoop目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E8%BF%90%E8%A1%8C%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.6.</span> <span class="nav-text">Hadoop运行的三种模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E7%A4%BA%E4%BE%8B-%E5%AE%98%E6%96%B9WordCount"><span class="nav-number">2.7.</span> <span class="nav-text">Hadoop本地模式示例(官方WordCount)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F-%E5%BC%80%E5%8F%91%E9%87%8D%E7%82%B9"><span class="nav-number">2.8.</span> <span class="nav-text">完全分布式运行模式(开发重点)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC-xsync"><span class="nav-number">2.8.1.</span> <span class="nav-text">编写集群分发脚本 xsync</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#scp-secure-copy-%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="nav-number">2.8.1.1.</span> <span class="nav-text">scp(secure copy) 安全拷贝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#rsync%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="nav-number">2.8.1.2.</span> <span class="nav-text">rsync远程同步工具</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#xsync-%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="nav-number">2.8.1.3.</span> <span class="nav-text">xsync 集群分发脚本</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SSH%E6%97%A0%E5%AF%86%E7%99%BB%E9%99%86%E9%85%8D%E7%BD%AE"><span class="nav-number">2.8.2.</span> <span class="nav-text">SSH无密登陆配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE"><span class="nav-number">2.8.3.</span> <span class="nav-text">集群配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BE%A4%E8%B5%B7%E9%9B%86%E7%BE%A4"><span class="nav-number">2.8.4.</span> <span class="nav-text">群起集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95"><span class="nav-number">2.8.5.</span> <span class="nav-text">集群基本测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="nav-number">2.8.6.</span> <span class="nav-text">配置历史服务器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86"><span class="nav-number">2.8.7.</span> <span class="nav-text">配置日志的聚集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93"><span class="nav-number">2.8.8.</span> <span class="nav-text">集群启动&#x2F;停止方式总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99Hadoop%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC"><span class="nav-number">2.8.9.</span> <span class="nav-text">编写Hadoop集群常用脚本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7%E8%AF%B4%E6%98%8E-%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="nav-number">2.8.10.</span> <span class="nav-text">常用端口号说明(面试题)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-%E9%9D%A2%E8%AF%95%E9%A2%98"><span class="nav-number">2.8.11.</span> <span class="nav-text">常用的配置文件(面试题)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="nav-number">2.8.12.</span> <span class="nav-text">集群时间同步</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">2.9.</span> <span class="nav-text">常见错误及解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%98%B2%E7%81%AB%E5%A2%99%E6%B2%A1%E5%85%B3%E9%97%AD-%E6%88%96%E8%80%85%E6%B2%A1%E6%9C%89%E5%90%AF%E5%8A%A8-YARN"><span class="nav-number">2.9.1.</span> <span class="nav-text">防火墙没关闭 , 或者没有启动 YARN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AF"><span class="nav-number">2.9.2.</span> <span class="nav-text">主机名称配置错误</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IP-%E5%9C%B0%E5%9D%80%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AF"><span class="nav-number">2.9.3.</span> <span class="nav-text">IP 地址配置错误</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ssh-%E6%B2%A1%E6%9C%89%E9%85%8D%E7%BD%AE%E5%A5%BD"><span class="nav-number">2.9.4.</span> <span class="nav-text">ssh 没有配置好</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#root-%E7%94%A8%E6%88%B7%E5%92%8Ctaki-%E4%B8%A4%E4%B8%AA%E7%94%A8%E6%88%B7%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4%E4%B8%8D%E7%BB%9F%E4%B8%80"><span class="nav-number">2.9.5.</span> <span class="nav-text">root 用户和taki 两个用户启动集群不统一</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9%E4%B8%8D%E7%BB%86%E5%BF%83"><span class="nav-number">2.9.6.</span> <span class="nav-text">配置文件修改不细心</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8D%E8%AF%86%E5%88%AB%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0"><span class="nav-number">2.9.7.</span> <span class="nav-text">不识别主机名称</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DataNode-%E5%92%8C-NameNode-%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%97%B6%E5%8F%AA%E8%83%BD%E5%B7%A5%E4%BD%9C%E4%B8%80%E4%B8%AA"><span class="nav-number">2.9.8.</span> <span class="nav-text">DataNode 和 NameNode 进程同时只能工作一个</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%E4%B8%8D%E7%94%9F%E6%95%88-%E7%B2%98%E8%B4%B4-Word-%E4%B8%AD%E5%91%BD%E4%BB%A4%E6%97%B6-%E9%81%87%E5%88%B0-%E5%92%8C%E9%95%BF%E2%80%93%E6%B2%A1%E5%8C%BA%E5%88%86%E5%BC%80-%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E5%A4%B1%E6%95%88"><span class="nav-number">2.9.9.</span> <span class="nav-text">执行命令不生效,粘贴 Word 中命令时,遇到-和长–没区分开.导致命令失效</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#jps-%E5%8F%91%E7%8E%B0%E8%BF%9B%E7%A8%8B%E5%B7%B2%E7%BB%8F%E6%B2%A1%E6%9C%89%EF%BC%8C%E4%BD%86%E6%98%AF%E9%87%8D%E6%96%B0%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4%EF%BC%8C%E6%8F%90%E7%A4%BA%E8%BF%9B%E7%A8%8B%E5%B7%B2%E7%BB%8F%E5%BC%80%E5%90%AF%E3%80%82"><span class="nav-number">2.9.10.</span> <span class="nav-text">jps 发现进程已经没有，但是重新启动集群，提示进程已经开启。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#jps-%E4%B8%8D%E7%94%9F%E6%95%88"><span class="nav-number">2.9.11.</span> <span class="nav-text">jps 不生效</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8088-%E7%AB%AF%E5%8F%A3%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A"><span class="nav-number">2.9.12.</span> <span class="nav-text">8088 端口连接不上</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UI%E6%B2%A1%E6%9D%83%E9%99%90"><span class="nav-number">2.9.13.</span> <span class="nav-text">UI没权限</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS-Shell%E5%91%BD%E4%BB%A4%E4%B8%8A%E4%BC%A0"><span class="nav-number">2.10.</span> <span class="nav-text">HDFS_Shell命令上传</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS%E7%9B%B4%E6%8E%A5%E6%93%8D%E4%BD%9C"><span class="nav-number">2.11.</span> <span class="nav-text">HDFS直接操作</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">muCyaKuCya</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">muCyaKuCya</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
